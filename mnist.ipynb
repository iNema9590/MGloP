{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3081412/1235930754.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('data/model_mnist.pth'))\n",
      "/tmp/ipykernel_3081412/1235930754.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dmem=torch.load('data/embedsmnist_DM.pt')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IF.train_model_mnist import *\n",
    "from proutils import *\n",
    "import numpy as np\n",
    "import kmedoids\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import accuracy_score, silhouette_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from aix360.algorithms.protodash import ProtodashExplainer\n",
    "from scipy.spatial.distance import cosine\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('data/model_mnist.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "ifem=np.load(\"data/influence_scores_mnist.npy\")\n",
    "dmem=torch.load('data/embedsmnist_DM.pt')\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Extract images and labels\n",
    "train_images = torch.stack([train_dataset[i][0] for i in range(len(train_dataset))])  # [N_train, 1, 28, 28]\n",
    "train_embeddings=model(train_images, emd=True).detach().numpy()\n",
    "train_labels = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))])\n",
    "test_images = torch.stack([test_dataset[i][0] for i in range(len(test_dataset))])    # [N_test, 1, 28, 28]\n",
    "test_embeddings=model(test_images, emd=True).detach().numpy()\n",
    "test_labels = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogate_fidelity(prototypes, X_test, mod_pred):\n",
    "    train_dataset = TensorDataset(X_test, mod_pred)\n",
    "    trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    smodel = fit_model(trainloader)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    smodel.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = torch.argmax(smodel(X_test), dim=1)\n",
    "        accuracy = (outputs == mod_pred).sum().item() / len(mod_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection matrix is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs.aau.dk/em63by/anaconda3/envs/mglop/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1600: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "  warnings.warn(\"k >= N for N * N square matrix. \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_samples=2 should be >= n_clusters=20.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m aide_em\u001b[38;5;241m=\u001b[39maide(ifem, train_embeddings, test_embeddings, \u001b[38;5;241m30\u001b[39m, coverage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m prs\u001b[38;5;241m=\u001b[39m\u001b[43mfind_representative_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m distances \u001b[38;5;241m=\u001b[39m cosine_similarity(test_embeddings, test_embeddings[prs])\n\u001b[1;32m      4\u001b[0m nearest_medoid_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(distances, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Influence_Function_Evaluation/Projects/MGloP/proutils.py:255\u001b[0m, in \u001b[0;36mfind_representative_samples\u001b[0;34m(test_embeddings, train_embeddings, ifem, N, iN, alpha)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Perform clustering\u001b[39;00m\n\u001b[1;32m    250\u001b[0m clustering \u001b[38;5;241m=\u001b[39m SpectralClustering(\n\u001b[1;32m    251\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39mN,  \u001b[38;5;66;03m# Adjust number of clusters as neededs\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     affinity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m    254\u001b[0m )\n\u001b[0;32m--> 255\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mclustering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Select representatives\u001b[39;00m\n\u001b[1;32m    258\u001b[0m representatives \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/cluster/_spectral.py:785\u001b[0m, in \u001b[0;36mSpectralClustering.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    764\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform spectral clustering on `X` and return cluster labels.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m        Cluster labels.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/base.py:753\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/cluster/_spectral.py:750\u001b[0m, in \u001b[0;36mSpectralClustering.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity_matrix_ \u001b[38;5;241m=\u001b[39m pairwise_kernels(\n\u001b[1;32m    746\u001b[0m         X, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity, filter_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    747\u001b[0m     )\n\u001b[1;32m    749\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m--> 750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m=\u001b[39m \u001b[43mspectral_clustering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffinity_matrix_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43meigen_solver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigen_solver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43meigen_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigen_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43massign_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/cluster/_spectral.py:383\u001b[0m, in \u001b[0;36mspectral_clustering\u001b[0;34m(affinity, n_clusters, n_components, eigen_solver, random_state, n_init, eigen_tol, assign_labels, verbose)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing label assignment using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00massign_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m assign_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 383\u001b[0m     _, labels, _ \u001b[38;5;241m=\u001b[39m \u001b[43mk_means\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m assign_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_qr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m     labels \u001b[38;5;241m=\u001b[39m cluster_qr(maps)\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:420\u001b[0m, in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, sample_weight, init, n_init, max_iter, verbose, tol, random_state, copy_x, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    274\u001b[0m     {\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m     return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m ):\n\u001b[1;32m    310\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform K-means clustering algorithm.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <k_means>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m        Returned only if `return_n_iter` is set to True.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m     est \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_n_iter:\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m est\u001b[38;5;241m.\u001b[39mcluster_centers_, est\u001b[38;5;241m.\u001b[39mlabels_, est\u001b[38;5;241m.\u001b[39minertia_, est\u001b[38;5;241m.\u001b[39mn_iter_\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1426\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1417\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1418\u001b[0m     X,\n\u001b[1;32m   1419\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1423\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1424\u001b[0m )\n\u001b[0;32m-> 1426\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1428\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m   1429\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1362\u001b[0m, in \u001b[0;36mKMeans._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m-> 1362\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_n_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_algorithm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_algorithm \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/mglop/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:859\u001b[0m, in \u001b[0;36m_BaseKMeans._check_params_vs_input\u001b[0;34m(self, X, default_n_init)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, default_n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;66;03m# n_clusters\u001b[39;00m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters:\n\u001b[0;32m--> 859\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    860\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be >= n_clusters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    861\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;66;03m# tol\u001b[39;00m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tol \u001b[38;5;241m=\u001b[39m _tolerance(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol)\n",
      "\u001b[0;31mValueError\u001b[0m: n_samples=2 should be >= n_clusters=20."
     ]
    }
   ],
   "source": [
    "aide_em=aide(ifem, train_embeddings, test_embeddings, 30, coverage=True)\n",
    "prs=find_representative_samples(test_embeddings, train_embeddings, ifem, 20, 30, alpha=0.6)\n",
    "distances = cosine_similarity(test_embeddings, test_embeddings[prs])\n",
    "nearest_medoid_indices = np.argmax(distances, axis=1)\n",
    "\n",
    "# def coverage(N, bin=False, popularity=True):\n",
    "#     covs=[]\n",
    "#     for i in np.unique(nearest_medoid_indices):\n",
    "#         idx=np.where(nearest_medoid_indices == i)[0]\n",
    "#         if popularity:\n",
    "#             gx=[i[0] for i in Counter(np.array(aide_em)[idx].flatten()).most_common(60)]\n",
    "#         else:\n",
    "#             gx=aide_em[prs[i]]\n",
    "#         for j in idx:\n",
    "#             if bin:\n",
    "#                 if len(set(aide_em[j]).intersection(set(gx)))>N:\n",
    "#                     covs.append(1)\n",
    "#                 else:\n",
    "#                     covs.append(0)\n",
    "#             else:\n",
    "#                 covs.append(len(set(aide_em[j]).intersection(set(gx)))/len(aide_em[j]))\n",
    "#     return sum(covs)/len(covs)\n",
    "\n",
    "# covs= [coverage(i, bin=True, popularity=False) for i in range(31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 60000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity to the number of influential sample to build the graph with\n",
    "mglop=Parallel(n_jobs=-1)(delayed(find_representative_samples)(test_embeddings, train_embeddings, ifem,20, i, alpha=0.6) for i in tqdm(range(5,41,5)))\n",
    "accs=[]\n",
    "fids=[]\n",
    "sil=[]\n",
    "sim=[]\n",
    "def compute_metrics(i):\n",
    "    acc = nearest_medoid_accuracy(test_embeddings, mod_pred, mglop[i])\n",
    "    fid=surrogate_fidelity(mglop[i], test_images, mod_pred)\n",
    "    sil = compute_prototype_silhouette_score(test_embeddings, mglop[i])\n",
    "    labels = cluster_by_prototypes(test_embeddings, mglop[i])\n",
    "    sim = expected_inter_cluster_similarity(test_embeddings, labels)\n",
    "    return acc,fid, sil, sim\n",
    "\n",
    "# Parallel computation\n",
    "results = Parallel(n_jobs=64)(delayed(compute_metrics)(i) for i in range(len(mglop)))\n",
    "\n",
    "# Unpack results into separate lists\n",
    "accs,fids, sil, sim = zip(*results)\n",
    "plt.plot(range(5,41,5), accs, marker='D', label='Faithfulness')\n",
    "plt.plot(range(5,41,5), fids, marker='*', label='Fidelity')\n",
    "plt.plot(range(5,41,5), sil, marker='x', label='Silhouette')\n",
    "plt.plot(range(5,41,5), sim, marker='o', label='Expected similarity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values=range(10,51, 5)\n",
    "def generate_prototypes(N):\n",
    "    explainer = ProtodashExplainer()\n",
    "    weights, protodash, _ = explainer.explain(test_embeddings, test_embeddings, m=N, kernelType='euclid')\n",
    "    \n",
    "    return {\n",
    "        \"mglop\": find_representative_samples(test_embeddings, train_embeddings, ifem, N, 15, alpha=0.6),\n",
    "        \"dknn\": find_prototypes(test_embeddings, mod_pred, N),\n",
    "        \"dm\": find_prototypes(dmem, mod_pred, N),\n",
    "        \"protodash\": protodash\n",
    "    }\n",
    "\n",
    "n_jobs = -1 \n",
    "all_protos = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(generate_prototypes)(N)\n",
    "    for N in tqdm(N_values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection\n",
    "\n",
    "algorithms = ['mglop', 'dknn', 'dm', 'protodash']\n",
    "intersections = {f\"{algo1} ∩ {algo2}\": [] for i, algo1 in enumerate(algorithms) for algo2 in algorithms[i + 1:]}\n",
    "\n",
    "# Extract intersections between algorithm outputs\n",
    "for i, outputs in enumerate(all_protos):\n",
    "    for j, algo1 in enumerate(algorithms):\n",
    "        for algo2 in algorithms[j + 1:]:\n",
    "            intersection_size = len(set(outputs[algo1]) & set(outputs[algo2]))\n",
    "            intersections[f\"{algo1} ∩ {algo2}\"].append(intersection_size)\n",
    "\n",
    "# Plotting the results\n",
    "line_styles = ['-', '--', '-.', ':', '-', '--']\n",
    "markers = ['o', 's', 'D', '^', 'v', 'P']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for (label, sizes), linestyle, marker in zip(intersections.items(), line_styles, markers):\n",
    "    plt.plot(N_values, sizes, linestyle=linestyle, marker=marker, label=label)\n",
    "\n",
    "plt.xlabel(\"Number of Prototypes (N)\")\n",
    "plt.ylabel(\"Intersection Size\")\n",
    "plt.title(\"Intersection Size vs Number of Elements (N) for Algorithm Outputs\")\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as a PDF\n",
    "# plt.savefig(\"Figures/intersection_plot.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_protos_np=np.array(all_protos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def assign_clusters(X, prototypes):\n",
    "\n",
    "    # Compute distance from each point to each prototype\n",
    "    distances = cdist(X, prototypes, metric='euclidean')\n",
    "    \n",
    "    # Assign each point to the cluster with minimum distance\n",
    "    labels = np.argmin(distances, axis=1)\n",
    "    return labels\n",
    "\n",
    "pairwise_aris = {\n",
    "    \"MGloP-DkNN\": [],\n",
    "    \"MGloP-DM\": [],\n",
    "    \"MGloP-PDash\": [],\n",
    "    \"DkNN-DM\": [],\n",
    "    \"DkNN-PDash\": [],\n",
    "    \"DM-PDash\": []\n",
    "}\n",
    "\n",
    "for i in range(len(all_protos_np)):\n",
    "    labels1 = assign_clusters(test_embeddings, test_embeddings[list(all_protos_np[i].values())[0]])\n",
    "    labels2 = assign_clusters(test_embeddings, test_embeddings[list(all_protos_np[i].values())[1]])\n",
    "    labels3 = assign_clusters(test_embeddings, test_embeddings[list(all_protos_np[i].values())[2]])\n",
    "    labels4 = assign_clusters(test_embeddings, test_embeddings[list(all_protos_np[i].values())[3]])\n",
    "    \n",
    "    \n",
    "    # Compute ARIs for all pairs\n",
    "    ari_12 = adjusted_rand_score(labels1, labels2)\n",
    "    ari_13 = adjusted_rand_score(labels1, labels3)\n",
    "    ari_14 = adjusted_rand_score(labels1, labels4)\n",
    "    ari_23 = adjusted_rand_score(labels2, labels3)\n",
    "    ari_24 = adjusted_rand_score(labels2, labels4)\n",
    "    ari_34 = adjusted_rand_score(labels3, labels4)\n",
    "    \n",
    "    # Append results\n",
    "    pairwise_aris[\"MGloP-DkNN\"].append(ari_12)\n",
    "    pairwise_aris[\"MGloP-DM\"].append(ari_13)\n",
    "    pairwise_aris[\"MGloP-PDash\"].append(ari_14)\n",
    "    pairwise_aris[\"DkNN-DM\"].append(ari_23)\n",
    "    pairwise_aris[\"DkNN-PDash\"].append(ari_24)\n",
    "    pairwise_aris[\"DM-PDash\"].append(ari_34)\n",
    "\n",
    "# Plot the ARI evolution for each pair\n",
    "plt.figure(figsize=(10, 6))\n",
    "for pair_name, ari_values in pairwise_aris.items():\n",
    "    plt.plot(N_values, ari_values, marker='o', label=pair_name)\n",
    "\n",
    "plt.title('ARI Evolution for Each Pair as Number of Prototypes Increases')\n",
    "plt.xlabel('Number of Prototypes (k)')\n",
    "plt.ylabel('ARI')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglop_ev=[]\n",
    "dmodels_ev=[]\n",
    "protodash_ev=[]\n",
    "dknn_ev=[]\n",
    "for i in range(len(all_protos_np)):\n",
    "    mglop_ev.append([nearest_medoid_accuracy(test_embeddings, mod_pred, list(all_protos_np[i].values())[0]), compute_prototype_silhouette_score(test_embeddings, list(all_protos_np[i].values())[0]), surrogate_fidelity(list(all_protos_np[i].values())[0], test_images, mod_pred)])\n",
    "    dknn_ev.append([nearest_medoid_accuracy(test_embeddings, mod_pred, list(all_protos_np[i].values())[1]), compute_prototype_silhouette_score(test_embeddings, list(all_protos_np[i].values())[1]),surrogate_fidelity(list(all_protos_np[i].values())[1], test_images, mod_pred)])\n",
    "    dmodels_ev.append([nearest_medoid_accuracy(test_embeddings, mod_pred, list(all_protos_np[i].values())[2]), compute_prototype_silhouette_score(test_embeddings, list(all_protos_np[i].values())[2]), surrogate_fidelity(list(all_protos_np[i].values())[2], test_images, mod_pred)])\n",
    "    protodash_ev.append([nearest_medoid_accuracy(test_embeddings, mod_pred, list(all_protos_np[i].values())[3]), compute_prototype_silhouette_score(test_embeddings, list(all_protos_np[i].values())[3]), surrogate_fidelity(list(all_protos_np[i].values())[3], test_images, mod_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_range=range(10,51,5)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(N_range, [item[2] for item in mglop_ev], marker='o', linestyle='-', label='MGLop Accuracy')\n",
    "plt.plot(N_range, [item[2] for item in dknn_ev], marker='s', linestyle='--', label='DKNN Accuracy')\n",
    "plt.plot(N_range, [item[2] for item in dmodels_ev], marker='D', linestyle='-.', label='DModels Accuracy')\n",
    "plt.plot(N_range, [item[2] for item in protodash_ev], marker='^', linestyle=':', label='Protodash Accuracy')\n",
    "\n",
    "plt.xlabel(\"Number of Prototypes (N)\")\n",
    "plt.ylabel(\"Fidelity\")\n",
    "plt.title(\"Surrogate Model Accuracy vs Number of Prototypes (N) for Different Algorithms\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.savefig(\"Figures/nearest_medoid_accuracy_plot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_range=range(10,51,5)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(N_range, [item[0] for item in mglop_ev], marker='o', linestyle='-', label='MGLop Accuracy')\n",
    "plt.plot(N_range, [item[0] for item in dknn_ev], marker='s', linestyle='--', label='DKNN Accuracy')\n",
    "plt.plot(N_range, [item[0] for item in dmodels_ev], marker='D', linestyle='-.', label='DModels Accuracy')\n",
    "plt.plot(N_range, [item[0] for item in protodash_ev], marker='^', linestyle=':', label='Protodash Accuracy')\n",
    "\n",
    "plt.xlabel(\"Number of Prototypes (N)\")\n",
    "plt.ylabel(\"Nearest Medoid Accuracy\")\n",
    "plt.title(\"Nearest Medoid Accuracy vs Number of Prototypes (N) for Different Algorithms\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.savefig(\"Figures/nearest_medoid_accuracy_plot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stability (Silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(N_range, [item[1] for item in mglop_ev], marker='o', linestyle='-', label='MGLop Silhouette Score')\n",
    "plt.plot(N_range, [item[1] for item in dknn_ev], marker='s', linestyle='--', label='DKNN Silhouette Score')\n",
    "plt.plot(N_range, [item[1] for item in dmodels_ev], marker='D', linestyle='-.', label='DModels Silhouette Score')\n",
    "plt.plot(N_range, [item[1] for item in protodash_ev], marker='^', linestyle=':', label='Protodash Silhouette Score')\n",
    "\n",
    "plt.xlabel(\"Number of Prototypes (N)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Score vs Number of Prototypes (N) for Different Algorithms\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.savefig(\"Figures/silhouette_score_plot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Inter-cluster similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "# Experiment with increasing number of prototypes\n",
    "num_prototypes_list = range(10, 51, 5)\n",
    "avg_similarities = []\n",
    "avg_similarities1 = []\n",
    "avg_similarities2 = []\n",
    "avg_similarities3 = []\n",
    "\n",
    "for i in tqdm(range(9)):\n",
    "    mglop=list(all_protos_np[i].values())[0]\n",
    "    dmodels=list(all_protos_np[i].values())[2]\n",
    "    dknn=list(all_protos_np[i].values())[1]\n",
    "    protodash=list(all_protos_np[i].values())[3]\n",
    "    labels = cluster_by_prototypes(test_embeddings, mglop)\n",
    "    labels1 = cluster_by_prototypes(test_embeddings, dknn)\n",
    "    labels2 = cluster_by_prototypes(test_embeddings, dmodels)\n",
    "    labels3 = cluster_by_prototypes(test_embeddings, protodash)\n",
    "    avg_similarity = expected_inter_cluster_similarity(test_embeddings, labels)\n",
    "    avg_similarity1 = expected_inter_cluster_similarity(test_embeddings, labels1)\n",
    "    avg_similarity2 = expected_inter_cluster_similarity(test_embeddings, labels2)\n",
    "    avg_similarity3 = expected_inter_cluster_similarity(test_embeddings, labels3)\n",
    "    avg_similarities.append(avg_similarity)\n",
    "    avg_similarities1.append(avg_similarity1)\n",
    "    avg_similarities2.append(avg_similarity2)\n",
    "    avg_similarities3.append(avg_similarity3)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_prototypes_list, avg_similarities, marker='o', label='MGloP')\n",
    "plt.plot(num_prototypes_list, avg_similarities1, marker='x', label='DkNN')\n",
    "plt.plot(num_prototypes_list, avg_similarities2, marker='*', label='Dmodels')\n",
    "plt.plot(num_prototypes_list, avg_similarities3, marker='D', label='ProtoDash')\n",
    "plt.xlabel('Number of Prototypes')\n",
    "plt.ylabel('Expected Inter-Cluster Similarity')\n",
    "plt.title('Expected Inter-Cluster Similarity vs Number of Prototypes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mglop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
